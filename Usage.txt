1) Processing the STARD data:

C:\Users\Tejas\Documents\qlesq_project\qlesq_prediction>python code/data-cleaning/stard_preprocessing_manager.py data/STARD_raw -a


2) Processing the CANBIND data:

C:\Users\Tejas\Documents\qlesq_project\qlesq_prediction>python code/data-cleaning/canbind_preprocessing_manager.py

note: before running this, go into canbind_preprocessing_manager.py and alter pathData to a correct pathing for the raw data (see below; will be different depending on the user)

    elif len(sys.argv) == 1:
        pathData = r'C:\Users\Tejas\Documents\qlesq_project\qlesq_prediction\data\canbind_raw_data'
        aggregate_and_clean(pathData, verbose=False)
        ygen(pathData)
        impute(pathData)
        convert_canbind_to_overlapping(pathData)


3) Create Overlapping Data from processed data:

C:\Users\Tejas\Documents\qlesq_project\qlesq_prediction>python code/data-cleaning/generate_overlapping_features.py -both data/STARD_raw/processed_data/final_xy_data_matrices data/canbind_raw_data/

4) Create y targets:

python code/create_targets.py data/STARD_raw/processed_data/final_xy_data_matrices/y_qlesq_77__final

python code/create_targets.py data/STARD_raw/processed_data/final_xy_data_matrices/y_qlesq_91__final

python code/create_targets.py data/canbind_raw_data/q-les-q/canbind_qlesq_y

5) Move Relevant Datasets to modelling folder:
python code/move_modelling.py

6) Create Train/Test Data:

python code/train_test_split.py X_77_qlesq_sr__final_extval.csv y_qlesq_77__final__targets.csv 

python code/train_test_split.py X_77_qlesq_sr__final.csv y_qlesq_77__final__targets.csv 

7) Optional: Running a GridSearch

Manually adjust grid_search.py for model of interest and params to explore

python code/grid_search.py X_train_77 y_train_77 (input data you want to optimize for)


8) Running an experiment:

Experiments are run via run_experiment.py. It utilizes classes so code in main() will need to be altered to contain models of your choice. The type of data is given as arguements to main().

9) Run an Evaluation on STARD and CANBIND holdout sets:

There are three options:
- Full feature evalution on STARD holdout   (eval_type ="full")
- Overlapping feature evaluation on STARD holdout (eval_type = "over")
- Overlapping feature evaluation on CANBIND holdout (eval_type = "canbind")

python code/run_evaluation [eval_type] [a name for the evaluation]



